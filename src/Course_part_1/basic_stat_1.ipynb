{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Основы статистики\n",
    "\n",
    "##  Конспект лекций\n",
    "\n",
    "Автор лекций: **Анатолий Карпов**\n",
    "\n",
    "Конспектировал: отрок Михаил Курочкин\n",
    "\n",
    "telegram: @mikhail_kurochkin\n",
    "instagram: mikhail_k17 если хотите вообще от души поблагодарить - подписка/лайк :)\n",
    "\n",
    "Дополнял: отрок Илья Дашков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "### Неделя 1\n",
    " - [Генеральная совокупность и выборка](#Генеральная-совокупность-и-выборка)\n",
    " - [Типы переменных](#Типы-переменных)\n",
    " - [Описательная статистика](#Описательная-статистика)\n",
    " - [Меры центральной тенденции](#Меры-центральной-тенденции)\n",
    "     - [Мода](#Мода)\n",
    "     - [Медиана](#Медиана)\n",
    "     - [Среднее значение](#Среднее-значение)\n",
    "     - [Примеры](#1.Примеры)\n",
    " - [Меры изменчивости](#Меры-изменчивости)\n",
    "    - [Размах](#Размах)\n",
    "    - [Дисперсия](#Дисперсия)\n",
    "    - [Квартили распределения](#Квартили-распределения)\n",
    "    - [Пример](#2.Пример)\n",
    " - [Нормальное распределение](#Нормальное-распределение)\n",
    "    - [Z-преобразование](#Z-преобразование)\n",
    "    - [Правило 3х-сигм](#Правило-3х-сигм)\n",
    "    - [Примеры](#3.Примеры)\n",
    " - [Центральная предельная теорема](#Центральная-предельная-теорема)\n",
    "    - [Примеры](#4.Примеры)\n",
    " - [Доверительные интервалы для среднего](#Доверительные-интервалы-для-среднего)\n",
    " - [Идея статистического вывода](#Идея-статистического-вывода)\n",
    "     - [Статистическая проверка гипотез](#Статистическая-проверка-гипотез)\n",
    "     - [p-уровень значимости](#p-уровень-значимости)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неделя 2\n",
    " - [T-распределение](#T-распределение)\n",
    "     - [Подробно про нормальное и t-распредление](#Подробно-про-нормальное-и-t-распредление)\n",
    "     - [Примеры](#5.Примеры)\n",
    " - [Сравнение двух средних; t-критерий Стьюдента](#Сравнение-двух-средних.-t-критерий-Стьюдента)\n",
    "     - [Примеры применения t-критерий Стьюдента](#Примеры-применения-t-критерий-Стьюдента)\n",
    "     - [Построение графиков](#6.-Примеры)\n",
    " - [Проверка распределения на нормальность](#Проверка-распределения-на-нормальность)\n",
    "     - [QQ-plot](#QQ-plot)\n",
    "     - [Примеры](#Примеры)\n",
    " - [Однофакторный дисперсионный анализ](#Однофакторный-дисперсионный-анализ)\n",
    " - [Множественные сравнения в ANOVA](#Множественные-сравнения-в-ANOVA)\n",
    "     - [почему мы не можем применить t-критерий для более двух выборок](#почему-мы-не-можем-применить-t-критерий-для-более-двух-выборок)\n",
    " - [Многофакторный ANOVA](#Многофакторный-ANOVA)\n",
    "   - [Двухфакторный дисперсионный анализ](#Двухфакторный-дисперсионный-анализ)\n",
    "   - [Взаимодействие факторов в ANOVA](#Взаимодействие-факторов-в-ANOVA)\n",
    "   - [Требования к данным](#Требования-к-данным)\n",
    "   - [Интерпрертация результатов](#Интерпрертация-результатов)\n",
    " - [АБ тесты и статистика](#АБ-тесты-и-статистика)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Неделя 3\n",
    "\n",
    " - [Корреляция](#Корреляция)\n",
    "     - [Ковариация](#Ковариация)\n",
    "     - [Примеры](#Примеры-3.1)\n",
    " - [Регрессия с одной независимой переменной](#Регрессия-с-одной-независимой-переменной)\n",
    " - [Гипотеза о значимости взаимосвязи и коэффициент детерминации](#Гипотеза-о-значимости-взаимосвязи-и-коэффициент-детерминации)\n",
    " - [Условия применения линейной регрессии с одним предиктором](#Условия-применения-линейной-регрессии-с-одним-предиктором)\n",
    " - [Задача предсказания значений зависимой переменной](#Задача-предсказания-значений-зависимой-переменной)\n",
    " - [Регрессионный анализ с несколькими независимыми переменными](#Регрессионный-анализ-с-несколькими-независимыми-переменными)\n",
    "     - [Пример расчёта и визуализации множественной регрессии](#Пример-расчёта-и-визуализации-множественной-регрессии)\n",
    " - [Выбор наилучшей модели](#Выбор-наилучшей-модели)\n",
    " - [Классификация: логистическая регрессия и кластерный анализ](#Классификация:-логистическая-регрессия-и-кластерный-анализ)\n",
    " - [GLM и продвинутые темы](##GLM-и-продвинутые-темы)\n",
    " - [Заключение](##Заключение)\n",
    "\n",
    "\n",
    "[Полезные ссылки](#Полезные-ссылки)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генеральная совокупность и выборка\n",
    " - **Генеральная совокупность** (от лат. generis — общий, родовой) — совокупность всех объектов, относительно которых предполагается делать выводы при изучении конкретной задачи. Далее ГС.\n",
    " - **Репрезентативная выборка** – это такая выборка, в которой все основные признаки генеральной совокупности, из которой извлечена данная выборка, представлены приблизительно в той же пропорции или с той же частотой, с которой данный признак выступает в этой генеральной совокупности.\n",
    "\n",
    "### Способы репрезентативной выборки:\n",
    " - **Простая случайная выборка** (simple random sample)\n",
    " - **Стратифицированная выборка** (stratified sample) – разделение ГС на страты (группы) а оттуда уже делается случайная выборка.\n",
    " - **Групповая выборка** (cluster sample) – похожие группы выбираются из выборки и далее делается случайная выборка (например, районы одного города)\n",
    " \n",
    "| групповая выборка                                                                                                                | Стратифицированная выборка                                                                              |\n",
    "|----------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------|\n",
    "| Выборка формируется только из несколько субпопуляций (кластеров)                                                                 | Выборка формируется из всех субпопуляций (страт)                                                        |\n",
    "| В пределах кластера элементы должны быть разнородны, тогда как поддерживается однородность или схожесть между разными кластерами | В пределах страты элементы должны быть однородны, а между стратами должна быть разнородность (различия) |\n",
    "| Схема выборки нужна только для кластеров, попавших в выборку                                                                     | Должна быть сформирована полная схема выборки для всех стратифицированных субпопуляций                  |\n",
    "| Повышает эффективность выборки, уменьшая стоимость                                                                               | Повышает точность                                                                                       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы переменных\n",
    "\n",
    " * **Количественные** – измеряемое (например, рост):\n",
    "     + **Непрерывные** – переменная принимает любое значение на опр. промежутке;\n",
    "     + **Дискретные** – только определенные значения (3.5 ребенка в семье не будет).\n",
    " * **Номинативные (качественные)**  – разделение испытуемых на группы, цифры как маркеры (например: 1 -женщины, 2 – мужчины). Цифры используются как имена групп, они не предназначены для расчётов. \n",
    " * **Ранговые** – похоже на номинативные, только возможны сравнения (быстрее/медленнее и т.п.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описательная статистика\n",
    "### Глоссарий:\n",
    " - **Эмпирические данные** - данные полученные опытным путём.\n",
    "\n",
    " - **Описательная (дескриптивная) статистика** - обработка данных полученных эмпирическим путём и их систематизация, наглядное представление в форме графиков, таблиц, а также их количественное описание посредством основных статистических показателей.\n",
    "\n",
    " - **Распределение вероятностей** - это закон, описывающий область значений случайной величины и вероятность её появления (частоту) в данной области. То есть насколько часто X появляется в данном диапазоне значений.\n",
    "\n",
    " - **Гистограмма частот** - ступенчатая функция показывающая насколько часто вероятно появление величины в указанном диапазоне значений.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меры центральной тенденции\n",
    "### Мода\n",
    "Это значение признака, которое встречается максимально часто. В выборке может быть несколько мод или одна мода.\n",
    "### Медиана\n",
    "Это значение признака, которое делит упорядочное множество пополам. Если множество содержит чётное количество элементов, то берётся среднее из двух серединных элементов упорядочного множества.\n",
    "### Среднее значение\n",
    "Cумма всех значений измеренного признака делится на количество измеренных значений.\n",
    "\n",
    "#### Свойства среднего значения\n",
    "$$M_{x + c} = \\frac{\\sum_{i=1}^{n}{(x_{i} + c)}}{n} = \\frac{\\sum_{i=1}^{n} x_{i}}{n} + \\frac{\\sum_{i=1}^{n} c}{n} = M_{x} + \\frac{nc}{n} = M_{x} + c$$\n",
    "\n",
    "$$M_{x * c} = \\frac{\\sum_{i=1}^{n}{(x_{i} * c)}}{n} = \\frac{c * \\sum_{i=1}^{n} x_{i}}{n} = c * M_{x}$$\n",
    "\n",
    "$$\\sum_{i=1}^{n} (x_{i} - M_{x}) = nM_{x} - nM_{x} = 0$$\n",
    "\n",
    "### 1.Примеры "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Расчёт моды, медианы и среднего с помощью библиотек numpy и scipy'''\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "sample = np.array([185, 175, 170, 169, 171, 175, 157, 172, 170, 172, 167, 173, 168, 167, 166,\n",
    "              167, 169, 172, 177, 178, 165, 161, 179, 159, 164, 178, 172, 170, 173, 171])\n",
    "mode = stats.mode(sample)\n",
    "# в numpy почему-то нет моды\n",
    "print('Мода:', mode[0])\n",
    "print('Медиана:', np.median(sample))\n",
    "print('Среднее:', np.mean(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Расчёт моды, медианы и среднего с помощью библиотеки pandas'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sample = pd.Series([185, 175, 170, 169, 171, 175, 157, 172, 170, 172, 167, 173, 168, 167, 166,\n",
    "              167, 169, 172, 177, 178, 165, 161, 179, 159, 164, 178, 172, 170, 173, 171])\n",
    "mode = np.array(sample.mode().array)\n",
    "print('mode:', mode)\n",
    "print('median:', sample.median())\n",
    "print('mean:', sample.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меры изменчивости\n",
    "### Размах\n",
    "Это разность между максимальным и минимальным значениям выборки. Крайне чувствителен к взбросам.\n",
    "### Дисперсия\n",
    "\n",
    "Это средний квадрат отклонений индивидуальных значений признака от их средней величины\n",
    "\n",
    "#### Для генеральной совокупности\n",
    "$$D = \\frac{\\sum_{i=1}^{n} (x_{i} - M_{x})^2}{n}$$\n",
    "Среднеквадратическое отклонение\n",
    "$$ \\sigma = \\sqrt{D}$$\n",
    "#### Для выборки\n",
    "$$D = \\frac{\\sum_{i=1}^{n} (x_{i} - M_{x})^2}{n-1}$$\n",
    "где 1 это количество степеней свободы\n",
    "Важно отменить, что среднеквадратическое отклонение для выборки обозначают по другому, как **sd** - standart deviation\n",
    "\n",
    "#### Ликбез: Почему именно квадрат, а не модуль или куб?\n",
    " Могу предположить, что линейное отклонение более чувствительно выбросам, квадратичное менее, кубическое — ещё менее чувствительно.\n",
    " Попробовал посчитать для 3-х выборок: [1,2,3,4,5], [1,2,3,4,50] и [1,2,3,4,500]:\n",
    "\n",
    " - Линейное: 2.5, 452.5 и 49502.5\n",
    " - Квадратичное: 1.58, 21.27 и 222.49\n",
    " - Кубическое: 1.36, 7.68, и 36.71\n",
    " \n",
    "Модуль не берут потому, что модуль - не гладкая функция. В нуле у модуля имеется \"излом\" из-за которого у производной происходит разрыв.\n",
    "А очень многие математические теоремы, которые наверняка потребуются дальше, работают только на гладких функциях.\n",
    "\n",
    "Вообще, с не гладкими функциями работать не любят. Там все становится сложнее. Поэтому берется квадрат.\n",
    "[Source](#https://stepik.org/lesson/8076/step/5?discussion=49741&unit=1356)\n",
    "\n",
    "#### Свойства дисперсии\n",
    "\n",
    "$$ D_{x+c} = D_x $$\n",
    "$$ D_{x*c} = D_x+c^2 $$\n",
    "\n",
    "### Квартили распределения\n",
    "**Квартили** - это три точки(значения признака), которые делят **упорядочное** множество данных на 4 равные части.\n",
    "\n",
    "**Box plot** - такой вид диаграммы в удобной форме показывает медиану, нижний и верхний квартили, минимальное и максимальное значение выборки и выбросы.\n",
    "\n",
    "<img src=\"../../img/boxplot.png\" width=400>\n",
    "\n",
    "Квартили и inter quartile range используют, чтобы оценить наличие выбросов. Алгоритм расчета - посчитали квартили, посчитали разницу между ними, вычислили теоретический максимум и минимум, сравнили с имеющимся и выяснили есть ли у вас выбросы и сколько их. Если много, то нужно анализировать и решать брать ли их в выборку или нет. \n",
    "\n",
    "### 2.Пример\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Расчитываем размах и стандартное отклонение с помощью numpy'''\n",
    "import numpy as np\n",
    "\n",
    "sample = np.array([185, 175, 170, 169, 171, 175, 157, 172, 170, 172, 167, 173, 168, 167, 166,\n",
    "              167, 169, 172, 177, 178, 165, 161, 179, 159, 164, 178, 172, 170, 173, 171])\n",
    "\n",
    "# The name of the function comes from the acronym for ‘peak to peak’.\n",
    "print(f'Range: {np.ptp(sample)} is equal max - min: {np.max(sample)- np.min(sample)}')\n",
    "\n",
    "# ddof - Delta Degrees of Freedom\n",
    "print(f'Standard deviation: {np.std(sample, ddof=1):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Диаграмма boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''с помощью диаграммы boxplot мы можем узнать медиану, 2 и 3 квартиль'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#пример графика boxplot\n",
    "plt.boxplot(sample, showfliers=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное распределение\n",
    "\n",
    "$$y = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\cdot e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}$$\n",
    "\n",
    " - Унимодально\n",
    " - Симметрично\n",
    " - Отклонения наблюдений от среднего подчиняются определённому вероятностному закону\n",
    " \n",
    "\n",
    "Нормальное распределение возникает в результате воздействия множества факторов, вклад каждого из которых очень мал.\n",
    "\n",
    "Для облегчения этого восприятия в 1873 году Фрэнсис Гальтон сделал устройство, которое в последствии назвали Доской Галтона (или квинкункс). Суть простая: сверху по середине подаются шарики, которые при прохождении нескольких уровней (например, 10-ти) на каждом уровне сталкиваются с препятствием, и при каждом столкновении отскакивают либо влево, либо вправо (с равной вероятностью).\n",
    "\n",
    "Как вы догадываетесь, результатом прохождения - это распределение, стремящееся к нормальному!\n",
    "\n",
    "Выглядит это так:\n",
    "\n",
    "<img src=\"../../img/гальтон.gif\" width=500>\n",
    "\n",
    "Или в виде кода:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Иммитация доски Гальтона в коде'''\n",
    "import seaborn as sns # подключаем библиотеку, модернизирующую mathplotlib для статистики\n",
    "\n",
    "data = dict() #словарь с набором итоговое положение - кол-во шариков\n",
    "N = 10000 # количество шариков\n",
    "levels = 20 # количество уровней\n",
    "\n",
    "for ball in range(N):\n",
    "    index = 0\n",
    "    for level in range(levels): #для каждого уровня а.к.а. выбора лево или право\n",
    "        index += np.random.choice([-1, 1]) #вычисляем итоговую позицию шарика в конце как сумму сдвижек всех выборов\n",
    "    data.setdefault(index, 0)# инициализируем \n",
    "    data[index] += 1\n",
    "    \n",
    "sns.barplot(x=list(data.keys()), y=list(data.values())); #создаём гистограмму"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-преобразование\n",
    "\n",
    "Преобразование полученных данных в стандартную Z-шкалу (Z-scores) со средним значением = 0 и дисперсией = 1. Чтобы привести к такому виду из каждого наблюдения нужно отнять среднее значение и разделить на стандартное отклонение. \n",
    "\n",
    "$$ Z_{i}=\\frac{x_{i} - \\bar{X}}{sd} $$\n",
    "\n",
    "Иногда нам необходимо рассчитать z - значение только для отдельно взятого наблюдения, чтоб выяснить насколько далеко оно отклоняется от среднего значения в единицах стандартного отклонения.\n",
    "\n",
    "### Правило 3х-сигм\n",
    "\n",
    "<img src=\"../../img/3-sigma.svg\">\n",
    "\n",
    "\n",
    "### 3.Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Считается, что значение IQ (уровень интеллекта) у людей имеет нормальное распределение\n",
    "со средним значением равным 100 и стандартным отклонением равным 15 (M = 100, sd = 15).\n",
    "Какой приблизительно процент людей обладает IQ > 125?\n",
    "'''\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "mean = 100\n",
    "std = 15\n",
    "IQ=120\n",
    "# sf - Survival function = (1 - cdf) - Cumulative distribution function\n",
    "print(f\"Только у {(stats.norm(mean, std).sf(IQ))*100:.2f}% людей, IQ>{IQ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Центральная предельная теорема\n",
    "\n",
    "Гласит, что множество средних выборок из генеральной совокупности (ГС необязательно иметь нормальное распределние) будут иметь нормальное распределение. Причём средняя этого распределения будет близко к средней генеральной совокупности, а стандарное отклонение этого распределение будет называться **стандартной ошибкой среднего** (se).\n",
    "\n",
    "Зная стандартное отклонение ГС и размер выборки мы можем рассчитать стандартную ошибку среднего.\n",
    "\n",
    "$$ se = \\frac{\\sigma}{\\sqrt{N}} $$\n",
    "\n",
    "где N - размер выборки. Если размер выборки достаточно большой (>30) и она является репрезативна, то вместо стандарного отклонения ГС мы можем взять стандарное отклонение выборки.\n",
    "\n",
    "$$ se = \\frac{sd}{\\sqrt{N}} $$\n",
    "\n",
    "Стандартная ошибка среднего - это среднеквадратическое отклонение распределения выборочных средних\n",
    "### 4.Примеры\n",
    "Проверим на практике все эти законы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# значения игральной кости\n",
    "dice = [1, 2, 3, 4, 5, 6]\n",
    "# количество бросков кости\n",
    "count = 6\n",
    "# размер генеральной совокупности\n",
    "sp_size = 100000\n",
    "# sp - Statistical population - генеральная совокупность\n",
    "sp = pd.Series(dtype=np.int64, index=range(sp_size))\n",
    "for i in range(sp_size):\n",
    "    throws_sum = 0\n",
    "    for throw in range(count):\n",
    "        throws_sum += np.random.choice(dice)\n",
    "    sp[i] = throws_sum\n",
    "\n",
    "sp.plot.hist(bins=(36-6), xlabel='Сумма костей', ylabel='Частота')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество выборок\n",
    "samples_count = 10\n",
    "# размер выборки\n",
    "sample_size = 200\n",
    "\n",
    "histos = {}\n",
    "for sample in range(samples_count):\n",
    "    histos[f'Выборка №{sample+1}'] = [np.random.choice(sp) for element in range(sample_size)]\n",
    "\n",
    "samples = pd.DataFrame(histos)\n",
    "\n",
    "samples.hist(figsize=(16, 10), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(hspace = 0.6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = samples.mean()\n",
    "print(f'сравним среднию ГС: {sp.mean()}')\n",
    "print(f'и среднию средних выборок: {means.mean()}')\n",
    "print('их разница:', abs(means.mean() - sp.mean()))\n",
    "print('и стандартная ошибка среднего:', means.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмём произвольную выборку \n",
    "sample = samples.iloc[0]\n",
    "print('sample mean:', sample.mean())\n",
    "print('sample SE: ', sample.std()/math.sqrt(sample.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.S. Важное замечание о ЦПТ номер 2.\n",
    "\n",
    "Пожалую самый сложный момент - это как мы так взяли и заменили стандартное отклонение генеральной совокупности на выборочное. Ну и что с того, что у нас выборка объемом больше 30 наблюдений, что за магическое число такое? \n",
    "\n",
    "Все правильно, никакой магии не происходит. И совсем скоро мы в этом окончательно разберемся. Как только пройдем тему t - распределения во втором модуле. Вот тут я подробно расписал, как же нам нужно рассчитывать стандартную ошибку среднего, если мы не знаем стандартное отклонение в генеральной совокупности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Доверительные интервалы для среднего\n",
    "\n",
    "Если мы имеем некоторую выборку и ГС, то мы **не можем точно** знать среднюю ГС, зная только среднее выборки. Однако **мы можем сказать, с некоторым процентом уверенности**, в каком интервале лежит средняя ГС. Понятно дело, что для нас лучше, чтобы этот интервал был как можно меньше, как это сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы знаем, средняя средних выборок, стремится к средней ГС, также мы знаем, что стандартная ошибка среднего описывает стандартное отклонение распределения средних выборок. Если мы возьмём случайную выборку $X$ и найдём её среднее $\\bar{X}$, а также вычислим стандартную ошибку $se$, то мы можем вычислить доверительный интевал $[\\bar{X} - 1.96*se; \\bar{X} + 1.96*se]$ который описывает среднюю ГС с некотором интервале с 95% доверия.\n",
    "\n",
    "Загадочное число **1,96** это количество сигм $\\sigma$ в нормальном распределение, необходимые, чтобы охватить **95%** значений в этом распределнии.\n",
    "\n",
    "<img src=\"../../img/norm_196.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Если мы рассчитали 95% доверительный интервал для среднего значения, это значит:\n",
    "\n",
    " - <font color='crimson'>Среднее значение в генеральной совокупности точно принадлежит рассчитанному доверительному интервалу.</font>\n",
    " - <font color='green'>Мы можем быть на 95% уверены, что среднее значение в генеральной совокупности принадлежит рассчитанному доверительному интервалу.</font>\n",
    " - <font color='green'>Если многократно повторять эксперимент, для каждой выборки рассчитывать свой доверительный интервал, то в 95 % случаев истинное среднее будет находиться внутри доверительного интервала.</font>\n",
    " - <font color='crimson'>Среднее значение в генеральной совокупности точно превышает нижнюю границу 95% доверительного интервала.</font>\n",
    " - <font color='crimson'>Если многократно повторять эксперимент, то 95 % выборочных средних значений будут принадлежать рассчитанному нами доверительному интервалу.</font>\n",
    " \n",
    " __Если из лекции усвоить разницу между средним ГС и средним выборки, а так же понять, что доверительный интервал строится для выборки, а не для ГС, то ответы в тесте легко определяются.__\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Вычисление 1.96 c помощью scipy'''\n",
    "from scipy import stats\n",
    "\n",
    "# 95%\n",
    "p = 0.95\n",
    "# так как у нас двухсторонний интервал, сделаем вычисление\n",
    "alpha = (1-p)/2\n",
    "# isf - Inverse survival function (inverse of sf) \n",
    "print(f'{stats.norm().isf(alpha):.2f} sigma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Рассчитайте 99% доверительный интервал для следующего примера: \n",
    "среднее = 10, стандартное отклонение = 5, размер выборки = 100\n",
    "'''\n",
    "from numpy import sqrt\n",
    "from scipy import stats\n",
    "\n",
    "p = 0.99\n",
    "mean = 10\n",
    "std = 5\n",
    "n = 100\n",
    "\n",
    "se = std/sqrt(n)\n",
    "alpha = (1-p)/2\n",
    "sigma = stats.norm().isf(alpha)\n",
    "сonfidence_interval = mean - sigma*se, mean + sigma*se\n",
    "print('[%.2f; %.2f]' % сonfidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идея статистического вывода\n",
    "### Статистическая проверка гипотез\n",
    "\n",
    "\n",
    "### p-уровень значимости\n",
    "\n",
    "p-уровень значимости - это вероятность получить такие или более выраженные различия при условии, что в генеральной совокупности никаких различий на самом деле нет.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-распределение\n",
    "\n",
    "Распределение Стьюдента по сути представляет собой сумму нескольких нормально распределенных случайных величин. Чем больше величин, тем больше верятность, что их сумма будет иметь нормальное распределение. Таким образом, количество суммируемых величин определяет важнейший параметр формы данного распредения - число степеней свободы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''График снизу показывает, как меняется форма распределения при увеличение количества степеней свободы.\n",
    "А также показывает приближение t-распредееления к нормальному по мере увеличения степеней свободы.'''\n",
    "from scipy.stats import t, norm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df1, df2, df3 = 1, 3, 3\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y1, y2, y3 = t.pdf(x, df=df1), t.pdf(x, df=df2), t.pdf(x, df=df3)\n",
    "y4 = norm.pdf(x)\n",
    "lable1, lable2, lable3 = 'df = '+str(df1), 'df = '+str(df2), 'd3 = '+str(df3)\n",
    "plt.title('графики t-распредления с разными степенями свободы')\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.plot(x, y3)\n",
    "plt.plot(x, y4, 'r:')\n",
    "plt.legend((lable1, lable2, lable3, 'norm'))\n",
    "plt.show()\n",
    "norm_p = stats.norm(0, 1).sf(2)*100\n",
    "t_p = stats.t(df3).sf(2)*100\n",
    "print(f\"Norm. P(x>2) = {norm_p:.2f}%\")\n",
    "print(f\"t. P(x>2) = {t_p:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "График плотности распределения Стьюдента, как и нормального распределения, является симметричным и имеет вид колокола, но с более «тяжёлыми» хвостами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подробно про нормальное и t-распредление\n",
    "\n",
    "В видео лекциях говорилось, что мы используем t-распределение в ситуации небольшого объема выборки. Необходимо более подробно пояснить, зачем это нужно.\n",
    "\n",
    "Вернемся к предельной центральной теореме, мы уже узнали, что если некий признак в генеральной совокупности распределен **нормально** со средним $\\mu$ и стандартным отклонением $\\sigma$, и мы будем многократно извлекать выборки одинакового размера n, и для каждой выборки рассчитывать, как далеко выборочное среднее $\\bar{X}$ ˉ\n",
    " отклонилось от среднего в генеральной совокупности в единицах стандартной ошибки среднего:\n",
    " \n",
    "\n",
    "$$\\large z = \\frac{\\bar{X} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}$$\n",
    "\n",
    "то эта величина z будет иметь стандартное нормальное распределение со средним равным нулю и стандартным отклонением равным единице.\n",
    "\n",
    "Обратите внимание, что для расчета стандартной ошибки мы используем именно стандартное отклонение в генеральной совокупности - $\\sigma$. Ранее мы уже обсуждали, что на практике $\\sigma$ нам практически никогда не известна, и для расчета стандартной ошибки мы используем выборочное стандартное отклонение.\n",
    "\n",
    "Так вот, строго говоря в таком случае распределение отклонения выборочного среднего и среднего в генеральной совокупности, деленного на стандартную ошибку, теперь будет описываться именно при помощи t - распределения.\n",
    "\n",
    "$$\\large t = \\frac{\\bar{X} - \\mu}{\\frac{sd}{\\sqrt{n}}}$$\n",
    "\n",
    "\n",
    "таким образом, в случае неизвестной $\\sigma$ мы **всегда будем иметь дело с t-распределением**. На этом этапе вы должны с негодованием спросить меня, почему же мы применяли z-критерий в первом модуле курса, для проверки гипотез, используя выборочное стандартное отклонение?\n",
    "\n",
    "Мы уже знаем, что при довольно большом объеме выборки (обычно в учебниках приводится правило, n > 30) t-распределение совсем близко подбирается к нормальному распределению:\n",
    "\n",
    "Поэтому иногда, для простоты расчетов говорится, что если n > 30, то мы будем использовать свойства нормального распределения для наших целей. Строго говоря, это конечно неправильный подход, который часто критикуют. В до компьютерную эпоху этому было некоторое объяснение, чтобы не рассчитывать для каждого n больше 30 соответствующее критическое значение t - распределения, статистики как бы округляли результат и использовали нормальное распределение для этих целей. Сегодня, конечно, с этим больше никаких проблем нет, и все статистические программы, разумеется, без труда рассчитают все необходимые показатели для t - распределения с любым числом степеней свободы. Действительно при выборках очень большого объема t - распределение практически не будет отличаться от нормального, однако, хоть и очень малые но различия все равно будут.\n",
    "\n",
    "Поэтому, правильнее будет сказать, что мы используем t - распределение не потому что у нас маленькие выборки, а потому что мы не знаем стандартное отклонение в генеральной совокупности. Поэтому в дальнейшем мы всегда будем использовать t - распределение для проверки гипотез, если нам неизвестно стандартное отклонение в генеральной совокупности, необходимое для расчета стандартной ошибки, даже если объем выборки больше 30.\n",
    "\n",
    "### 5.Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''На выборке в 15 наблюдений при помощи одновыборочного t-теста\n",
    "проверяется нулевая гипотеза: μ=10 \n",
    "и рассчитанное t-значение равняется -2 (t = -2), то p-уровень значимости  (двусторонний) равен:\n",
    "'''\n",
    "from scipy import stats\n",
    "\n",
    "t = -2\n",
    "n = 15\n",
    "df = n - 1\n",
    "\n",
    "p = 2 * stats.t.sf(abs(t), df)\n",
    "print(f'p = {p:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение двух средних. t-критерий Стьюдента\n",
    "\n",
    "t-критерий Стьюдента — общее название для статистических тестов, в которых статистика критерия имеет распределение Стьюдента. Наиболее часто t-критерии применяются для проверки равенства средних значений в двух выборках. Нулевая гипотеза предполагает, что средние равны (отрицание этого предположения называют гипотезой сдвига). Для применения данного критерия необходимо, чтобы исходные данные имели нормальное распределение. \n",
    "\n",
    "$$ t = \\frac{\\bar{X_1} - \\bar{X_2}}{se}$$\n",
    "\n",
    "$$ se = \\sqrt{\\frac{sd_1^2}{n_1} + \\frac{sd_2^2}{n_2}} $$\n",
    "\n",
    "Откуда берётся такая формула $se$?:\n",
    "\n",
    "$$ (se_1)^2 = (\\frac{sd_1}{\\sqrt{n_1}})^2 = \\frac{sd_1^2}{n_1} $$\n",
    " \n",
    "То есть:\n",
    "\n",
    "$$ se = \\sqrt{\\frac{sd_1^2}{n_1} + \\frac{sd_2^2}{n_2}} = \\sqrt{se_1^2 + se_2^2} $$\n",
    "\n",
    "причем ответ на вопрос, почему верно это равенство, кроется в свойстве дисперсии: дисперсия суммы независимых случайных величин равна сумме их дисперсий. а отклонение - это корень из дисперсии. отсюда ваша последняя формула"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры применения t-критерий Стьюдента\n",
    "**Пример 1.** Первая выборка — это пациенты, которых лечили препаратом А. Вторая выборка — пациенты, которых лечили препаратом Б. Значения в выборках — это некоторая характеристика эффективности лечения (уровень метаболита в крови, температура через три дня после начала лечения, срок выздоровления, число койко-дней, и т.д.) Требуется выяснить, имеется ли значимое различие эффективности препаратов А и Б, или различия являются чисто случайными и объясняются «естественной» дисперсией выбранной характеристики.\n",
    "\n",
    "**Пример 2.** Первая выборка — это значения некоторой характеристики состояния пациентов, записанные до лечения. Вторая выборка — это значения той же характеристики состояния тех же пациентов, записанные после лечения. Объёмы обеих выборок обязаны совпадать; более того, порядок элементов (в данном случае пациентов) в выборках также обязан совпадать. Такие выборки называются связными. Требуется выяснить, имеется ли значимое отличие в состоянии пациентов до и после лечения, или различия чисто случайны.\n",
    "\n",
    "**Пример 3.** Первая выборка — это поля, обработанные агротехническим методом А. Вторая выборка — поля, обработанные агротехническим методом Б. Значения в выборках — это урожайность. Требуется выяснить, является ли один из методов эффективнее другого, или различия урожайности обусловлены случайными факторами.\n",
    "\n",
    "**Пример 4.** Первая выборка — это дни, когда в супермаркете проходила промо-акция типа А (красные ценники со скидкой). Вторая выборка — дни промо-акции типа Б (каждая пятая пачка бесплатно). Значения в выборках — это показатель эффективности промо-акции (объём продаж, либо выручка в рублях). Требуется выяснить, какой из типов промо-акции более эффективен.\n",
    "\n",
    "### 6. Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import t\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "array1 = np.array([84.7, 105.0, 98.9, 97.9, 108.7, 81.3, 99.4, 89.4, 93.0,\n",
    "                   119.3, 99.2, 99.4, 97.1, 112.4, 99.8, 94.7, 114.0, 95.1, 115.5, 111.5])\n",
    "array2 = np.array([57.2, 68.6, 104.4, 95.1, 89.9, 70.8, 83.5, 60.1, 75.7,\n",
    "                   102.0, 69.0, 79.6, 68.9, 98.6, 76.0, 74.8, 56.0, 55.6, 69.4, 59.5])\n",
    "\n",
    "# считаем количество элементов, среднее, стандартное отклонение и стандартную ошибку\n",
    "df = pd.DataFrame({'Выборка №1':array1, 'Выборка №2':array2}).agg(['mean','std','count','sem']).transpose()\n",
    "df.columns = ['Mx','SD','N','SE']\n",
    "\n",
    "# рассчитываем 95% интервал отклонения среднего\n",
    "p = 0.95\n",
    "K = t.ppf((1 + p)/2, df['Mx']-1)\n",
    "df['interval'] = K * df['SE']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#строим графики, boxplot из изначальных данных array1, array2,  доверительные интервалы из датафрейма df\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(14, 9))\n",
    "\n",
    "# график boxplot\n",
    "bplot1 = ax1.boxplot([array1, array2],\n",
    "                     vert=True,  # создаем вертикальные боксы\n",
    "                     patch_artist=True, # для красоты заполним цветом боксы квантилей\n",
    "                     labels=['Выборка №1', 'Выборка №2']) # используется для задания значений выборок в случае с boxplot\n",
    "\n",
    "# график доверительных интервалов\n",
    "bplot2 = ax2.errorbar(x=df.index, y=df['Mx'], yerr=df['interval'],\\\n",
    "                      color=\"black\", capsize=3, marker=\"s\", markersize=4, mfc=\"red\", mec=\"black\", fmt ='o')\n",
    "\n",
    "# раскрасим boxplot  \n",
    "colors = ['pink', 'lightgreen']\n",
    "for patch, color in zip(bplot1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    \n",
    "# добавим общие для каждого из графиков данные\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_title('Температура плавления ДНК двух типов')\n",
    "    ax.set_xlabel('Сравнение двух выборок')\n",
    "    ax.set_ylabel('Температура F')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача \n",
    "\n",
    "Рассчитайте доверительный интервал основываясь на знании t - распределения для среднего значения температуры плавления ДНК у первого вида:\n",
    "\n",
    "$$ \\bar{X}=89,9\\quad sd=11,3\\quad n=20 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from math import sqrt\n",
    "\n",
    "mean = 89.9\n",
    "sd = 11.3\n",
    "n = 20\n",
    "# степень свободы\n",
    "df = n - 1\n",
    "# 95% доверительный интервал\n",
    "p = 0.95\n",
    "alpha = 1-p\n",
    "# стандартная ошибка\n",
    "se = sd/sqrt(n)\n",
    "\n",
    "# ppf - Percent point function\n",
    "# делим на два, так как по умолчанию функция считает для одного конца, а нам надо для двух\n",
    "t_value = stats.t(df).ppf(1-(alpha/2))\n",
    "\n",
    "# доверительный интервал \n",
    "сonfidence_interval = (mean-t_value*se, mean+t_value*se)\n",
    "print('[%.2f; %.2f]' % сonfidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые премии Оскар за лучшую мужскую и женскую роль были вручены в 1929. Данные гистограммы демонстрируют распределение возраста победителей с 1929 по 2014 год (100 мужчин, 100 женщин). Используя t - критерий проверьте, можно ли считать наблюдаемые различия в возрасте между лучшими актрисами и актерами  статистически достоверными.\n",
    "\n",
    "Средний возраст мужчин равен 45, sd = 9.\n",
    "\n",
    "Средний возраст женщин равен 34, sd = 10.\n",
    "\n",
    "<img src=\"../../img/oscar.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "from numpy import sqrt\n",
    "\n",
    "mean_m, mean_f = 45, 34\n",
    "sd_m, sd_f = 9, 10\n",
    "N = 100\n",
    "\n",
    "se = sqrt((sd_m ** 2)/N + (sd_f ** 2)/N)\n",
    "t_value = (mean_m - mean_f)/se\n",
    "\n",
    "p = t.sf(t_value, N-2)\n",
    "print(f'p={p}')\n",
    "if p >= 0.05:\n",
    "    print('Мы НЕ можем отклонить нулевую гипотезу')\n",
    "else:\n",
    "    print('Мы можем отклонить нулевую гипотезу')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка распределения на нормальность\n",
    "\n",
    "### QQ-plot\n",
    "\n",
    "### Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "mu, sigma = 10, 4\n",
    "n = 1000 # с ростом числа точек в распределении qq-plot стремится к прямой\n",
    "sequence = np.random.normal(mu, sigma, n)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('QQ Plot', fontsize=18)\n",
    "\n",
    "# Q-Q Plot graph\n",
    "stats.probplot(sequence, dist=\"norm\", plot=ax1)\n",
    "ax1.set_title(\"Normal Q-Q Plot\")\n",
    "\n",
    "# normal distribution histogram + distribution\n",
    "count, bins, _ = ax2.hist(sequence, 25, density=True)\n",
    "p_x = 1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (bins - mu)**2 / (2 * sigma**2) )\n",
    "ax2.plot(bins, p_x, color='r')\n",
    " \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Однофакторный дисперсионный анализ\n",
    "\n",
    "Рассмотренный ранее **t-критерий Стьюдента** (равно как и его непараметрические аналоги) предназначен для сравнения исключительно **двух совокупностей**. В таком случае мы можем применять однофакторный дисперсионный анализ.  Та переменная, которая будет разделять наших испытуемых или наблюдения на группы (номинативная переменная с нескольким градациями) называется **независимой переменной**. А та количественная переменная, по степени выраженности которой мы сравниваем группы, называется **зависимая переменная**. \n",
    "\n",
    "\n",
    "$$ SS_{total} = \\sum_{j=1}^{p}{\\sum_{i=1}^{n_j}{(x_{ij} - \\bar{x})^2}} = SS_{between} + SS_{within} $$\n",
    "$$ SS_{between} = \\sum_{j=1}^{p}{n_j{(\\bar{x}_j - \\bar{x})^2}} $$\n",
    "$$ SS_{within} = \\sum_{j=1}^{p}{\\sum_{i=1}^{n_j}{(x_{ij} - \\bar{x}_j)^2}} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "# Выборки которые надо сравнить\n",
    "data = pd.DataFrame({\n",
    "           'a': [3, 1, 2],\n",
    "           'b': [5, 3, 4],\n",
    "           'c': [7, 6, 5]\n",
    "          })\n",
    "data.boxplot()\n",
    "print('Нулевая гипотеза:', '='.join(data))\n",
    "print('Альтернативная гипотеза:', f'!({\"=\".join(data)})')\n",
    "# общая средняя\n",
    "grand_mean = data.values.flatten().mean()\n",
    "# отклонение групповых средний от общей средней\n",
    "ssb = sum(data[group].size * (group_mean - grand_mean)**2  for group, group_mean in data.mean().items())\n",
    "# отклонения значений в внутри группы от средней группы\n",
    "ssw = sum(sum((x - group_mean)**2 for x in data[group]) for group, group_mean in data.mean().items())\n",
    "\n",
    "groups = data.shape[1]\n",
    "dfb = groups - 1\n",
    "dfw = data.size - groups\n",
    "# межгрупповой средний квадрат  \n",
    "mssb = ssb/dfb\n",
    "# внутригрупповой средний квадрат\n",
    "mssw = ssw/dfw\n",
    "\n",
    "f_value = mssb/mssw\n",
    "\n",
    "p = stats.f.sf(f_value, dfb, dfw)\n",
    "print('Результат:')\n",
    "if p < 0.05:\n",
    "    print('отклоняем нулевую гипотезу')\n",
    "else:\n",
    "    print('НЕ отклоняем нулевую гипотезу')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Множественные сравнения в ANOVA\n",
    "\n",
    "В отличие от t-критерия, позволяет сравнивать средние значения трёх и более групп. Разработан Р. Фишером для анализа результатов экспериментальных исследований. \n",
    "\n",
    "В литературе также встречается обозначение **ANOVA** (от англ. **AN**alysis **O**f **VA**riance) - дисперсионный анализ\n",
    "\n",
    "**Почему мы не можем применить t-критерий для более двух выборок применяя его попарно к каждой выбрке?**\n",
    "\n",
    "Чтобы выяснить это, сделаем эксперемент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "\n",
    "\n",
    "def pair_t(samples, alpha) -> np.bool:\n",
    "    '''\n",
    "    Парный t-критерий, если все переданные выборки\n",
    "    попарно взяты из одной ГС, возвращает True\n",
    "    '''\n",
    "    n_samples = samples.shape[0]   \n",
    "    n_combinations = n_samples*(n_samples - 1)//2 # число комбинациий для сранения по t-критерию, см https://ru.wikipedia.org/wiki/Сочетание \n",
    "    result = np.zeros(n_combinations, dtype=bool)\n",
    "    k = 0\n",
    "    for i in range(n_samples):\n",
    "        for j in range(i+1, n_samples):\n",
    "            N = samples[i].size\n",
    "            std_err = np.sqrt((samples[i].std()**2)/N + (samples[j].std()**2)/N)\n",
    "            t_value = (samples[i].mean() - samples[j].mean())/std_err\n",
    "            p = 2*t.sf(x=t_value, df=2*N-2) # умножаем на два, так как смотрим на два хвоста распределения \n",
    "            result[k] = (p >= alpha)\n",
    "            k += 1\n",
    "    return np.all(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_t_test(repeat, n_samples, sample_size, ax, alpha=0.05):\n",
    "    '''\n",
    "    функция показывает, сколько у нас будет ложных результатов, при парном сравнение множества выборок\n",
    "    с помощью t-критерия\n",
    "    \n",
    "    repeat, n_samples, sample_size = количество повторов, количество выборок в каждом повторе, размер выборки\n",
    "    ax - для рисования\n",
    "    '''\n",
    "    result = np.zeros(repeat, dtype=bool)\n",
    "    for i in range(repeat):\n",
    "        samples = random.randn(n_samples, sample_size)\n",
    "        result[i] = pair_t(samples, alpha)\n",
    "    \n",
    "    unique, counts = np.unique(result, return_counts=True)\n",
    "    percentage = counts/result.size\n",
    "    ax.pie(percentage, normalize=False, labels=unique, autopct='%.0f%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=4, figsize=(20, 5))\n",
    "n_samples = [2, 4, 8, 16]\n",
    "fig.suptitle('Процент ошибок (False) при попарном сравнение выборок t-критерием')\n",
    "\n",
    "for n, ax in zip(n_samples, axs):\n",
    "    pair_t_test(repeat=1000, n_samples=n, sample_size=100, ax=ax)\n",
    "    ax.set_title(f'{n} samples')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы и ожидаем, степень ошибки примерно должна быть равна **5%**, при сравнении **двух выборок** из одной ГС с помощью t-критерия с p-уровнем значимости **95%**. \n",
    "\n",
    "Если мы возмём больше выборок то процент ошибок будет возрастать с каждым увеличением числа выборок примерно как отношение сочетаний нового числа выборок к предыдущему, что совершенно неприемлемо.\n",
    "\n",
    "Причина такого возрастания ошибки в расмотрении всё большего числа комбинаций. Так как наше условие проверки множества выборок требует различия хотя бы пары, вероятность того, что это произойдёт при увеличении числа сравниваемых выборок стремится к единице.\n",
    "\n",
    "Решение этой проблемы - поправки на множественное сравнение для p-уровня значимости. А самая популярная такая поправка - поправка Бонферрони."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Поправка Бонферрони\n",
    "\n",
    "Поправка Бонферрони весьма интуитивна. Если вероятность ошибки растёт пропорционально числу сочетаний рассматриваемых в эксперименте выборок - $C^2_n$, то есть числу проверяемых гипотез, то нужно ужесточить критерий $\\alpha$ так же пропорционально этому числу: $\\alpha' = \\alpha / C^2_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применим поправку Бонферрони\n",
    "fig, axs = plt.subplots(ncols=4, figsize=(20, 4))\n",
    "n_samples = [2, 4, 8, 16]\n",
    "fig.suptitle('Процент ошибок при попарном сравнение выборок t-критерием с корректировкой уровня значимости')\n",
    "\n",
    "for n, ax in zip(n_samples, axs):\n",
    "    alpha = 0.05/((n*(n-1))/2) # ужесточили критерий\n",
    "    pair_t_test(1000, n, 100, ax, alpha)\n",
    "    ax.set_title(f'{n} samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С новым показателем $\\alpha$ процент ошибки стал правтикчески одинаковым вне зависимости от числа рассматриваемых гипотез - это успех!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в данном случае эта будет сверх-консервативная корректировавка, которая имеет меньше вероятность найти реальные значения. По сути мы **уменьшаем шанс получить ошибку I рода, но увеличиваем шанс на ошибку II рода**. То есть мы уничтожаем очень много \"полезных\" результатов в эксперименте.\n",
    "\n",
    "<img src='../../img/error_types.jpeg'/>\n",
    "\n",
    "Так не применять какую-то корректировку для множественного сравнения невозможно, но сильно увеличивать ошибку II рода не хочется, были разработаны более подходящие способы поправки, чем поправка Бонферрони. Пример более продвинутого метода - **критерий Тьюки**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Критерий Тьюки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Многофакторный ANOVA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двухфакторный дисперсионный анализ\n",
    "\n",
    "В случе двухфакторного анализа (он же Two-way analysis of variance) мы можем учитывать взаимосвязь нашей зависимой переменной не с одним фактором (одной номининативной перменной), а с двумя.\n",
    "\n",
    "Основная идея двухфаткорного дисперсионного анализа сводится к тому, что теперь у нас общая изменчивость $SS_{total}$ складывается из следующих четырёх компонент:\n",
    "\n",
    "$ SS_{total} = SSW + SSB_A + SSB_B + SSB_{A}*SSB_{B}, $ \n",
    "\n",
    "где $SSW$ - это внутригрупповая изменчивость, $SSB_A$ - изменчивость, обусловленная влиянием первого фактора, $SSB_B$ - изменчивость, обусловленная влиянием второго фактора, $SSB_{A}*SSB_{B}$ - изменчивость, обусловленная взаимодействием двух факторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пример\n",
    "Атеросклероз довольно опасное заболевание причина ишемической болезни сердца и инсультов. Анализ экспрессии генов лейкоцитов позволяет предсказать вероятность развития данного заболевания. В эксперименте исследовался уровень экспрессии в зависимости от возраста пациентов и дозировки лекарства аторвастатина. Понятно, что в данном исследовании экпрессия (expr) это зависимая переменная, а два фактора - возраст (age) и дозировка лекарства (dose).\n",
    "\n",
    "Рассмотрим две гипотезы $H_0$: \n",
    "1. Отсутвует статистически значимое влияние возраста на экспрессию гена.\n",
    "2. Отсутвует статистически значимое влияние дозировки лекраства на экспрессию гена.\n",
    "\n",
    "Для анализа можно разделить выборку на 4 подгруппы - молодые с высокой дозировкой, молодые с низкой дозировкой, пожилые с высокой дозировкой, и пожилые с низкой дозировкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим график измерений\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ather_data = pd.read_csv('../../data/atherosclerosis.csv') # считываем файл с данными\n",
    "sns.set_theme(rc={'figure.figsize':(15, 10)}) # задаем размеры выводимого графика\n",
    "pplot = sns.pointplot(x='dose', y='expr', hue='age', palette='bright', dodge=0.1, capsize=.1, data=ather_data)# строим график с помощью seaborn\n",
    "\n",
    "# меняем названия титула, оси х и оси у\n",
    "plt.title('Экспрессия гена в зависимости от дозировки и возраста пациентов', fontsize=25)\n",
    "plt.xlabel('Дозировка', fontsize=20)\n",
    "plt.ylabel('Уровень экспрессии', fontsize=20)\n",
    "\n",
    "bars = ('низкая', 'высокая')\n",
    "x_pos = np.arange(len(bars))\n",
    "plt.xticks(x_pos, bars, fontsize=15) # меняем названия отложенных по оси х значений\n",
    "\n",
    "# меняем \"Легенду\", ту, что в верхнем правом углу\n",
    "leg_handles = pplot.get_legend_handles_labels()[0]\n",
    "pplot.legend(leg_handles, ['молодые', 'пожилые'], title='Возраст', title_fontsize=20, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывод результатов дисперсионного анализа\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "df = pd.read_csv('../../data/atherosclerosis.csv')\n",
    "print('Dataframe sample:\\n', df.head(10), '\\n')\n",
    "print('Dataframe types:\\n', df.dtypes, '\\n')\n",
    "print('Dataframe stats:\\n', df.describe(), '\\n')\n",
    "\n",
    "#разделим выборку на подгруппы\n",
    "df_young_high = df[(df['age'] == 1) & (df['dose'] == 'D1')]['expr']\n",
    "df_young_low  = df[(df['age'] == 1) & (df['dose'] == 'D2')]['expr']\n",
    "df_old_high   = df[(df['age'] == 2) & (df['dose'] == 'D1')]['expr']\n",
    "df_old_low    = df[(df['age'] == 2) & (df['dose'] == 'D2')]['expr']\n",
    "\n",
    "# посчитаем число наблюдений\n",
    "N = df['expr'].count()\n",
    "N_young_high = df_young_high.count()\n",
    "N_young_low  = df_young_low.count()\n",
    "N_old_high   = df_old_high.count()\n",
    "N_old_low    = df_old_low.count()\n",
    "\n",
    "# посчтиаем средние значения\n",
    "Mx = df['expr'].mean()\n",
    "Mx_young_high = df_young_high.mean()\n",
    "Mx_young_low  = df_young_low.mean()\n",
    "Mx_old_high   = df_old_high.mean()\n",
    "Mx_old_low    = df_old_low.mean()\n",
    "Mx_young = (N_young_high*Mx_young_high + N_young_low*Mx_young_low)/(N_young_high + N_young_low)\n",
    "Mx_old = (N_old_high*Mx_old_high + N_old_low*Mx_old_low)/(N_old_high + N_old_low)\n",
    "Mx_high = (N_young_high*Mx_young_high + N_old_high*Mx_old_high)/(N_young_high + N_old_high)\n",
    "Mx_low = (N_young_low*Mx_young_low + N_old_low*Mx_old_low)/(N_young_low + N_old_low)\n",
    "\n",
    "# посчитаем стандартные отлонения среднего\n",
    "SD = df['expr'].std()\n",
    "SD_young_high = df_young_high.std()\n",
    "SD_young_low  = df_young_low.std()\n",
    "SD_old_high   = df_old_high.std()\n",
    "SD_old_low    = df_old_low.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Характеристики исследумых подгрупп:\n",
    "| Возраст | Дозировка | N  | Mx    | SD  |  \n",
    "| ------- | --------- | -- | ----- | --- |  \n",
    "| молодые | высокая   | 16 | 104,8 | 5,8 | \n",
    "| молодые | низкая    | 16 | 105,5 | 4,4 | \n",
    "| пожилые | высокая   | 16 | 101   | 5,1 | \n",
    "| пожилые | низкая    | 16 | 102,3 | 5,1 | \n",
    "\n",
    "N - число элементов, Mx - математическое ожидание, SD - стандратное отклонение среднего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем суммы квадратов\n",
    "SS_age = ((Mx - Mx_young)**2)*(N_young_high + N_young_low) + ((Mx - Mx_old)**2)*(N_old_high + N_old_low) # sum of squares for age factor\n",
    "print(f'Сумма квадратов по возрасту: {round(SS_age,1)}')\n",
    "      \n",
    "SS_dose = ((Mx - Mx_high)**2)*(N_young_high + N_old_high) + ((Mx - Mx_low)**2)*(N_young_low + N_old_low) # sum of squares for dose factor\n",
    "print(f'Сумма квадратов по дозе: {round(SS_dose,1)}')\n",
    "\n",
    "SS_within = ((df_young_high - Mx_young_high)**2).sum() + ((df_young_low - Mx_young_low)**2).sum() + ((df_old_high - Mx_old_high)**2).sum() + ((df_old_low - Mx_old_low)**2).sum()\n",
    "print(f'Сумма квадратов внутри групп: {round(SS_within,1)}')\n",
    "\n",
    "SS = ((df['expr'] - Mx)**2).sum()\n",
    "print(f'Полная сумма квадратов: {round(SS,1)}')\n",
    "\n",
    "SS_age_dose = SS - SS_within - SS_age - SS_dose\n",
    "print(f'Сумма квадратов взаимодействия факторов: {round(SS_age_dose,1)}')\n",
    "\n",
    "# рассчитаем степени свободы\n",
    "Df_age = 2 - 1\n",
    "Df_dose = 2 - 1\n",
    "Df_age_dose = Df_age*Df_dose\n",
    "Df_within = N - 4\n",
    "Df = Df_within + Df_age + Df_dose + Df_age_dose\n",
    "\n",
    "# рассчитаем средние квадраты\n",
    "MS_within = SS_within / Df_within\n",
    "MS_age = SS_age / Df_age\n",
    "MS_dose = SS_dose / Df_dose\n",
    "MS = SS / Df\n",
    "\n",
    "print(f'Среднее квадратов по возрасту: {round(MS_age,2)}')\n",
    "print(f'Среднее квадратов по дозе: {round(MS_dose,2)}')\n",
    "\n",
    "# рассчитаем F-score\n",
    "Fs_age = MS_age / MS_within\n",
    "Fs_dose = MS_dose / MS_within\n",
    "\n",
    "print(f'F-score по возрасту: {round(Fs_age,2)}')\n",
    "print(f'F-score по дозе: {round(Fs_dose,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты дисперсионного анализа:\n",
    "|           | Df | Sum Sq | Mean Sq | F value | Pr(>F) |  \n",
    "| ----      | -- | ------ | ------- | ------- | ------ |\n",
    "| Age       | 1  | 197,5  | 197,45  | 7.45*   | 0,008  |\n",
    "| Dose      | 1  | 16,9   | 16,91   | 0,64    | 0,42   | \n",
    "| Residuals | 61 | 1591,2 | 26,08   |         |        | \n",
    "\n",
    "---\n",
    "\\* В оригинале, на слайдах лекций бьло указано число 7,57 для F-значения возраста, расчёт не подтверждает это значение, оно было исправлено как опечатка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Найдём площадь под графиком соответсвующего F-распределения для каждого фактора:\\n')\n",
    "\n",
    "print(f'Для возраста: F({Df_age},{Df_within}) = {round(Fs_age,2)}, p < 0.05')\n",
    "PrF_age = 1 - stats.f.cdf(Fs_age, Df_age, Df_within)\n",
    "print(f'Следовательно веротяность превышения этой величины: Pr(>F) = {round(PrF_age,3)}')\n",
    "if PrF_age < alpha:\n",
    "    print('Отбрасываем 1-ую нулевую гипотезу, возраст влияет на экспрессию гена\\n')\n",
    "else: \n",
    "    print('Принимаем 1-ую нулевую гипотезу, возраст не влияет на экспрессию гена\\n')\n",
    "    \n",
    "print(f'Для дозы: F({Df_dose},{Df_within}) = {round(Fs_dose,2)}, p < 0.05')\n",
    "PrF_dose = 1 - stats.f.cdf(Fs_dose, Df_dose, Df_within)\n",
    "print(f'Следовательно веротяность превышения этой величины: Pr(>F) = {round(PrF_dose,3)}')\n",
    "if PrF_dose < alpha:\n",
    "    print('Отбрасываем 2-ую нулевую гипотезу, доза лекраства влияет на экспрессию гена\\n')\n",
    "else: \n",
    "    print('Принимаем 2-ую нулевую гипотезу, доза лекраства не влияет на экспрессию гена\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Примечение. \n",
    "# Здесь ANOVA был выполнен по шагам для целей обучения, однако он, конечно уже давно был автоматизирован.\n",
    "# Например, с помощью python модуля statsmodels подобный анализ можно было бы сделать в две строки кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взаимодействие факторов в ANOVA\n",
    "\n",
    "Возможна ситуация, когда каждый из факторов по отдельности не влияет значимо на наши данные, однако факторы совместно - влияют.\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Исследователей интересовало влияние инъекции некоторого гормона на показатель концентрации кальция в плазме крови у птиц с учетом их пола. В таблице представлены данные экспериментальной и контрольной группы.\n",
    "\n",
    "Рассмотрим три гипотезы $H_0$: \n",
    "1. Отсутвует статистически значимое влияние инъекции некоторого гормона на концентрации кальция в плазме крови.\n",
    "2. Отсутвует статистически значимое влияние пола птицы на концентрации кальция в плазме крови.\n",
    "3. Отсутвует статистически значимое влияние взаимодействия инъекции некоторого гормона и пола птицы на концентрации кальция в плазме крови.\n",
    "\n",
    "Для анализа можно разделить выборку на 4 подгруппы - нет инъекции и пол птицы мужской, нет инъекции пол птицы женский, сделана инъекция пол птицы мужской, сделана инъекция и пол птицы женский."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построим график измерений\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "birds_data = pd.read_csv('../../data/birds.csv') # считываем файл с данными\n",
    "sns.set_theme(rc={'figure.figsize':(15, 10)}) # задаем размеры выводимого графика\n",
    "pplot = sns.pointplot(x='hormone', y='var4', hue='sex', dodge=0.1, capsize=.1, data=birds_data)# строим график с помощью seaborn\n",
    "\n",
    "# меняем названия титула, оси х и оси у\n",
    "plt.title('Исследование концентрации калия в плазме крови птиц', fontsize=25)\n",
    "plt.xlabel('Инъекция гормона', fontsize=20)\n",
    "plt.ylabel('Концентрация', fontsize=20)\n",
    "\n",
    "bars = ('Введена', 'Не введена')\n",
    "x_pos = np.arange(len(bars))\n",
    "plt.xticks(x_pos, bars, fontsize=15) # меняем названия отложенных по оси х значений\n",
    "\n",
    "# меняем \"Легенду\", ту, что в верхнем правом углу\n",
    "leg_handles = pplot.get_legend_handles_labels()[0]\n",
    "pplot.legend(leg_handles, ['Мужской', 'Женский'], title='Пол птиц', title_fontsize=20, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# вывод результатов дисперсионного анализа\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "df = pd.read_csv('../../data/birds.csv')\n",
    "print('Dataframe sample:\\n', df.head(10), '\\n')\n",
    "print('Dataframe types:\\n', df.dtypes, '\\n')\n",
    "print('Dataframe stats:\\n', df.describe(), '\\n')\n",
    "\n",
    "#разделим выборку на подгруппы\n",
    "df_nhrm_male   = df[(df['hormone'] == 0) & (df['sex'] == 0)]['var4']\n",
    "df_nhrm_female = df[(df['hormone'] == 0) & (df['sex'] == 1)]['var4']\n",
    "df_yhrm_male   = df[(df['hormone'] == 1) & (df['sex'] == 0)]['var4']\n",
    "df_yhrm_female = df[(df['hormone'] == 1) & (df['sex'] == 1)]['var4']\n",
    "\n",
    "# посчитаем число наблюдений\n",
    "N = df['var4'].count()\n",
    "N_nhrm_male = df_nhrm_male.count()\n",
    "N_nhrm_female  = df_nhrm_female.count()\n",
    "N_yhrm_male = df_yhrm_male.count()\n",
    "N_yhrm_female  = df_yhrm_female.count()\n",
    "\n",
    "# посчтиаем средние значения\n",
    "Mx = df['var4'].mean()\n",
    "Mx_nhrm_male = df_nhrm_male.mean()\n",
    "Mx_nhrm_female  = df_nhrm_female.mean()\n",
    "Mx_yhrm_male = df_yhrm_male.mean()\n",
    "Mx_yhrm_female  = df_yhrm_female.mean()\n",
    "Mx_nhrm = (N_nhrm_male*Mx_nhrm_male + N_nhrm_female*Mx_nhrm_female)/(N_nhrm_male + N_nhrm_female)\n",
    "Mx_yhrm = (N_yhrm_male*Mx_yhrm_male + N_yhrm_female*Mx_yhrm_female)/(N_yhrm_male + N_yhrm_female)\n",
    "Mx_male = (N_nhrm_male*Mx_nhrm_male + N_yhrm_male*Mx_yhrm_male)/(N_nhrm_male + N_yhrm_male)\n",
    "Mx_female = (N_nhrm_female*Mx_nhrm_female + N_yhrm_female*Mx_yhrm_female)/(N_nhrm_female + N_yhrm_female)\n",
    "\n",
    "# посчитаем стандартные отлонения среднего\n",
    "SD = df['var4'].std()\n",
    "SD_nhrm_male = df_nhrm_male.std()\n",
    "SD_nhrm_female  = df_nhrm_female.std()\n",
    "SD_yhrm_male = df_yhrm_male.std()\n",
    "SD_yhrm_female  = df_yhrm_female.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Характеристики исследумых подгрупп:\n",
    "| Инъекция | Пол       | $N$  | $M_x$    | $SD$  |  \n",
    "| -------  | --------- | -- | ----- | --- |  \n",
    "| нет      | женский   | 16 | 19,98 | 3,7 | \n",
    "| нет      | женский   | 16 | 17,6  | 2,4 | \n",
    "| да       | мужской   | 16 | 17,3  | 2,9 | \n",
    "| да       | мужской   | 16 | 19,7  | 3,4 | \n",
    "\n",
    "где $N$ - число элементов, $M_x$ - математическое ожидание среднего, $SD$ - стандратное отклонение среднего."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посчитаем суммы квадратов\n",
    "SS_hormone = ((Mx - Mx_nhrm)**2)*(N_nhrm_male + N_nhrm_female) + ((Mx - Mx_yhrm)**2)*(N_yhrm_male + N_yhrm_female) # sum of squares for hormone factor\n",
    "print(f'Сумма квадратов по наличию гормона в крови: {round(SS_hormone,1)}')\n",
    "      \n",
    "SS_sex = ((Mx - Mx_male)**2)*(N_nhrm_male + N_yhrm_male) + ((Mx - Mx_female)**2)*(N_nhrm_female + N_yhrm_female) # sum of squares for dose factor\n",
    "print(f'Сумма квадратов по полу: {round(SS_sex,1)}')\n",
    "\n",
    "SS_within = ((df_nhrm_male - Mx_nhrm_male)**2).sum() + ((df_nhrm_female - Mx_nhrm_female)**2).sum() + ((df_yhrm_male - Mx_yhrm_male)**2).sum() + ((df_yhrm_female - Mx_yhrm_female)**2).sum()\n",
    "print(f'Сумма квадратов внутри групп: {round(SS_within,1)}')\n",
    "\n",
    "SS = ((df['var4'] - Mx)**2).sum()\n",
    "print(f'Полная сумма квадратов: {round(SS,1)}')\n",
    "\n",
    "SS_hormone_sex = SS - SS_within - SS_hormone - SS_sex\n",
    "print(f'Сумма квадратов взаимодействия факторов: {round(SS_hormone_sex,1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# рассчитаем степени свободы\n",
    "Df_hormone = 2 - 1\n",
    "Df_sex = 2 - 1\n",
    "Df_hormone_sex = Df_hormone*Df_sex\n",
    "Df_within = N - 4\n",
    "Df = Df_within + Df_hormone + Df_sex + Df_hormone_sex\n",
    "\n",
    "# рассчитаем средние квадраты\n",
    "MS_within = SS_within / Df_within\n",
    "MS_hormone = SS_hormone / Df_hormone\n",
    "MS_sex = SS_sex / Df_sex\n",
    "MS_hormone_sex = SS_hormone_sex / Df_hormone_sex\n",
    "MS = SS / Df\n",
    "\n",
    "print(f'Среднее квадратов по наличию гормона в крови: {round(MS_hormone,2)}')\n",
    "print(f'Среднее квадратов по полу: {round(MS_sex,2)}')\n",
    "\n",
    "# рассчитаем F-score\n",
    "Fs_hormone = MS_hormone / MS_within\n",
    "Fs_sex = MS_sex / MS_within\n",
    "Fs_hormone_sex = MS_hormone_sex / MS_within\n",
    "\n",
    "print(f'F-score по наличию гормона в крови: {round(Fs_hormone,2)}')\n",
    "print(f'F-score по полу: {round(Fs_sex,2)}')\n",
    "print(f'F-score по наличию гормона в крови и полу: {round(Fs_hormone_sex,2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты дисперсионного анализа:\n",
    "|              | $Df$ | $Sum\\text{ }Sq$ | $Mean\\text{ }Sq$ | $F$ | $Pr(>F)$ |  \n",
    "| ----         | -- | ------ | ------- | ------- | ------ |\n",
    "| Hormone      | 1  | 0,8    | 0,85    | 0,087   | 0,7697 |\n",
    "| Sex          | 1  | 0,1    | 0,12    | 0,012   | 0,9123 | \n",
    "| Hormone: sex | 1  | 89,5   | 89,48   | 9,136   | 0,0037 | \n",
    "| Residuals    | 60 | 587,7  | 9,8     |         |        | \n",
    "\n",
    "где $Df$ - число степеней свободы, $Sum\\text{ }Sq$ - сумма квадратов, $Mean\\text{ }Sq$ - среднее квадратов, $F$ - F-значение, $Pr(>F)$ - вероятность для распределения Фишера с соответсвующими степенями свободы принять значение равное или большее чем F-значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Найдём площадь под графиком соответсвующего F-распределения для каждого фактора:\\n')\n",
    "\n",
    "print(f'Для наличию гормона в крови: F({Df_hormone},{Df_within}) = {round(Fs_hormone,2)}, p < 0.05')\n",
    "PrF_hormone = 1 - stats.f.cdf(Fs_hormone, Df_hormone, Df_within)\n",
    "print(f'Следовательно веротяность превышения этой величины: Pr(>F) = {round(PrF_hormone,3)}')\n",
    "if PrF_hormone < alpha:\n",
    "    print('Отбрасываем 1-ую нулевую гипотезу, введение гормона не влияет на концентраицю кальция в плазме\\n')\n",
    "else: \n",
    "    print('Принимаем 1-ую нулевую гипотезу, введение гормона не влияет на концентраицю кальция в плазме\\n')\n",
    "    \n",
    "print(f'Для дозы: F({Df_sex},{Df_within}) = {round(Fs_sex,2)}, p < 0.05')\n",
    "PrF_sex = 1 - stats.f.cdf(Fs_sex, Df_sex, Df_within)\n",
    "print(f'Следовательно веротяность превышения этой величины: Pr(>F) = {round(PrF_sex,3)}')\n",
    "if PrF_sex < alpha:\n",
    "    print('Отбрасываем 2-ую нулевую гипотезу, пол птицы влияет на концентраицю кальция в плазме\\n')\n",
    "else: \n",
    "    print('Принимаем 2-ую нулевую гипотезу, пол птицы не влияет на концентраицю кальция в плазме\\n')\n",
    "    \n",
    "print(f'Для дозы: F({Df_hormone_sex},{Df_within}) = {round(Fs_hormone_sex,2)}, p < 0.05')\n",
    "PrF_hormone_sex = 1 - stats.f.cdf(Fs_hormone_sex, Df_hormone_sex, Df_within)\n",
    "print(f'Следовательно веротяность превышения этой величины: Pr(>F) = {round(PrF_hormone_sex,3)}')\n",
    "if PrF_hormone_sex < alpha:\n",
    "    print('Отбрасываем 3-ю нулевую гипотезу, взаимодейтсиве введение гормона и пола птицы влияет на концентраицю кальция в плазме\\n')\n",
    "else: \n",
    "    print('Принимаем 3-ю нулевую гипотезу, взаимодейтсиве введение гормона и пола птицы не влияет на концентраицю кальция в плазме\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Требования к данным"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпрертация результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## АБ тесты и статистика\n",
    "\n",
    "Мы подробно изучили теоретические аспекты статистических методов. Пришло время узнать, как статистика применяется на практике для реальных исследований и экспериментов. \n",
    "\n",
    "АБ тестирование - это проведение экспериментов при помощи статистики, пожалуй, самый яркий пример того, зачем статистика нужна в реальной жизни!) A/B тесты - один из основных инструментов в продуктовой аналитике. Этот метод маркетингового исследования заключается в том, что контрольная группа элементов сравнивается с набором тестовых групп, где один или несколько показателей изменены для того, чтобы выяснить, какие из изменений улучшают целевой показатель. Например, мы можем поменять цвет кнопки для регистрации с красного на синий и сравнить, насколько это будет эффективно. \n",
    "\n",
    "Предлагаю вашему вниманию интервью с Никитой Маршалкиным, Data Scientist'ом ВКонтакте.\n",
    "\n",
    "Мы обсудили, как устроены АБ тесты ВКонтакте, а именно:\n",
    "\n",
    " Как работают системы сплитования\n",
    " Работают ли обычные статистические тесты на big data, и какие подводные камни там есть\n",
    " Особенности АБ тестов в социальных сетях\n",
    "Где научиться мастерски проводить АБ тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После [интервью с Никитой](https://www.youtube.com/watch?v=gljfGAkgX_o) мы собрали источники, которые он одобряет и использует в работе с A/B тестами (а некоторые даже написаны им лично!):\n",
    "\n",
    "Крутая [книга](https://experimentguide.com/) о том, как спланировать и провести своё первое A/B тестирование\n",
    "\n",
    "[Подборка](https://exp-platform.com/) примеров применения A/B тестов в индустрии: как топовая литература на тему, так и интервью от сотрудников крупных компаний, применяющих A/B тесты в работе\n",
    "\n",
    "Пошаговый, написанный с Никитой в соавторстве [гайдлайн](https://medium.com/@vktech/practitioners-guide-to-statistical-tests-ed2d580ef04f?fbclid=IwAR0Q7Gb-YmHG0Cg28IMC6RdBcjwqM466HaB4c-CtpXd03N-XyNzv9N5sWF0) для создания A/B тестов на языке Python:\n",
    "\n",
    "[Статья](https://research.google/pubs/pub43157/), описывающая как определять, комбинировать и объединять метрики (и комбинации из 2-3 метрик) с высокой прогнозирующей способностью таким образом, чтобы уменьшать их число и снижать вариативность\n",
    "\n",
    "[Работа](https://arxiv.org/abs/1404.7530), рассматривающая различные подходы к планированию и созданию рандомизированных экспериментов, чтобы не получить мнимые отличия на этапе дизайна\n",
    "\n",
    "Краткие [конспекты](https://research.fb.com/publications/top-challenges-from-the-first-practical-online-controlled-experiments-summit/) докладов исследователей и практиков из области анализа данных с конференции KDD 2019, где можно почерпнуть новаторские решения в планировании экспериментов для бизнеса\n",
    "\n",
    "Краткое [руководство](https://onlineuserengagement.github.io/) как правильно выстроить работу b2c: на какие метрики необходимо смотреть и как их учитывать для улучшения работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Корреляция\n",
    "\n",
    "### Ковариация \n",
    "Мера **линейной** зависимости двух случайных величин (ко - совместная, вариация - изменчивость).\n",
    "\n",
    "Если ковариация положительна, то с ростом значений одной случайной величины, значения второй имеют тенденцию возрастать, а если знак отрицательный — то убывать.\n",
    "\n",
    "$$ \\mathrm{cov}(x, y) = \\frac{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}}{N - 1} $$\n",
    "где $N$ - количество случайных величин, а $1$ - количество степеней свободы.\n",
    "\n",
    "### Корреляция\n",
    "Только по **абсолютному** значению ковариации **нельзя судить** о том, **насколько сильно величины взаимосвязаны**, так как масштаб ковариации зависит от их дисперсий. Значение ковариации можно нормировать, поделив её на произведение среднеквадратических отклонений (квадратных корней из дисперсий) случайных величин. Полученная величина называется **коэффициентом корреляции Пирсона**, который всегда находится в интервале от $−1$ до $1$:\n",
    "\n",
    "$$ r(x, y) = \\frac{\\mathrm{cov}(x, y)}{\\sigma_x\\sigma_y}$$\n",
    "\n",
    "Положительное значение $r(x, y)$ сигнализирует о **положительной корреляции** двух переменных $x$, $y$, а отрицательный - об **отрицательной корреляции**. Если значение $r(x, y)$ равно или близко нулю, это скорее всего говорит о том, что переменные $x, y$ между собой не взаимосвязаны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подробнее про формулу корреляции\n",
    "\n",
    "Давайте остановимся на формуле коэффициента корреляции, которую мы получили:\n",
    "$$ r(x, y) = \\frac{\\mathrm{cov}(x, y)}{\\sigma_x\\sigma_y}$$\n",
    "запишем формулу чуть подробнее и выполним возможные преобразования:\n",
    "\n",
    "$$ r(x, y) = \\frac{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}}{(N - 1)\\sqrt{\\sum\\limits_{i=1}^{N}{\\frac{(x_i - \\bar{x})^2}{N-1}}}\\sqrt{\\sum\\limits_{i=1}^{N}{\\frac{(y_i - \\bar{y})^2}{N-1}}}} $$\n",
    "\n",
    "теперь вынесем $1/(N - 1)$ из под корней \n",
    "\n",
    "$$ r(x, y) = \\frac{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}}{(N - 1)\\frac{1}{(N-1)}\\sqrt{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})^2}}\\sqrt{\\sum\\limits_{i=1}^{N}{(y_i - \\bar{y})^2}}} $$\n",
    "\n",
    "и сократим $(N - 1)$\n",
    "\n",
    "$$ r(x, y) = \\frac{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sqrt{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})^2}}\\sqrt{\\sum\\limits_{i=1}^{N}{(y_i - \\bar{y})^2}}} $$\n",
    "\n",
    "таким образом, мы сократили $N - 1$ в знаменателе и получили финальную формулу для коэффициента корреляции, которую вы часто сможете встретить в учебниках:\n",
    "\n",
    "$$ r(x, y) = \\frac{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sqrt{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})^2}\\sum\\limits_{i=1}^{N}{(y_i - \\bar{y})^2}}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коэффициент детерминации\n",
    "Коэффициент детерминации, который обозначается как $R^2$, показывает, в какой степени дисперсия переменной обусловлена \"влиянием\" другой переменной.\n",
    "\n",
    "Равен квадрату коэффициента корреляции Пирсона, а значит лежит в промежутке от $[0,1]$:\n",
    "$$\n",
    "R^2 = r^2(x,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Демонстрация работы ковариации и корреляции'''\n",
    "import numpy as np\n",
    "import random as r\n",
    "\n",
    "def cov(x, y):\n",
    "    assert x.size == y.size\n",
    "    return ((x - x.mean()) * (y - y.mean())).sum()/(x.size - 1)\n",
    "\n",
    "def cor(x, y):\n",
    "    return cov(x, y)/(np.std(x, ddof=1)*np.std(y, ddof=1))\n",
    "\n",
    "# функция имитирущая случаные факторы\n",
    "# р - настолько существенным будет случайный фактор\n",
    "def randomize(arr, p):\n",
    "    alpha = np.max(arr) - np.min(arr)\n",
    "    res = np.zeros(arr.shape)\n",
    "    for i, v in enumerate(arr):\n",
    "        sign = 1 if r.choice([True, False]) else -1\n",
    "        res[i] = v + sign*alpha*r.random()*p\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(30))\n",
    "y = randomize(x, 0.1)\n",
    "y1 = randomize(x, 0.5)\n",
    "y2 = randomize(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 3))\n",
    "ax1.scatter(x, y)\n",
    "ax2.scatter(x, y1)\n",
    "ax3.scatter(x, y2)\n",
    "ax1.set_title('высокая корреляция')\n",
    "ax2.set_title('средняя корреляция')\n",
    "ax3.set_title('низкая корреляция')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "cov1: {cov(x, y):.2f}\n",
    "cov2: {cov(x, y1):.2f}\n",
    "cov3: {cov(x, y2):.2f}\n",
    "\n",
    "cor1: {cor(x, y):.2f}\n",
    "cor2: {cor(x, y1):.2f}\n",
    "cor3: {cor(x, y2):.2f}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Позже, при рассмотрении линейной регрессии, мы обсудим применение t-теста для проверки гипотезы о равенстве нулю корреляции между двумя пременными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессия с одной независимой переменной\n",
    "\n",
    "В этой и следующих главах мы научимся работать  с **одномерным регрессионным анализом**, который позволяет проверять гипотезы о взаимосвязи одной  количественной зависимой переменной и нескольких независимых.\n",
    "\n",
    "Сначала мы познакомимся с самым простым вариантом -  простой **линейной регрессией**, при помощи которой можно исследовать взаимосвязь двух переменных. Затем перейдем к множественной регрессии с несколькими независимыми переменными.\n",
    "\n",
    "Линейная регрессия (англ. Linear regression) — используемая в статистике регрессионная модель зависимости одной (объясняемой, зависимой) переменной $y$ от другой или нескольких других переменных (факторов, регрессоров, независимых переменных) $x$ с **линейной функцией зависимости**.\n",
    "\n",
    "В общем виде функция линейной регрессии выглядит как:\n",
    "\n",
    "$$ y = b_0 + b_1x $$\n",
    "$b_0$ - intercept значение пересечения линии с осью Y \n",
    "\n",
    "$b_1$ - slope задаёт наклон линии регрессии\n",
    "\n",
    "строят регрессионную прямую методом наименьших квадратов (МНК)\n",
    "\n",
    "МНК - это способ нахождения оптимальных параметров линейной регресссии ($b_0$,  $b_1$), таких, что сумма квадратов ошибок (остатков) была минимальная.\n",
    "\n",
    "Расчёт параметров идёт по таким формулам:\n",
    "\n",
    "$$ b_1 = \\frac{sd_y}{sd_x}r_{xy} $$\n",
    "$$ b_0 = \\bar{Y} - b_1\\bar{X} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Демонстрация МНК'''\n",
    "b1 = y1.std()/x.std()*cor(x, y1)\n",
    "b0 = y1.mean() - b1*x.mean()\n",
    "f = lambda x: b0 + b1*x\n",
    "y_pred = f(x)\n",
    "plt.scatter(x, y1)\n",
    "plt.plot(x, y_pred, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Гипотеза о значимости взаимосвязи и коэффициент детерминации\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условия применения линейной регрессии с одним предиктором"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Применение регрессионного анализа и интерпретация результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''''\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../../data/states.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть данные по штатам с различными значениями:\n",
    " - **metro_res** - процент населения живущие в столице\n",
    " - **white** - процент белого населения\n",
    " - **hs_grad** - процент людей со образованием\n",
    " - **poverty** - уровень бедности\n",
    " - **female_house** - процент домов, где есть домохозяйки \n",
    " \n",
    "Исследуем связь уровня образования и бедности, где бедность будет зависимой переменной (ЗП), а уровень образования независимой переменной (НП).\n",
    "Нам нужно решить три задачи:\n",
    "\n",
    "1. Нужно построить линейную модель, которая наилучшим образом будет описывать наши данные.\n",
    "\n",
    "Предполагаем, что в нашем случае это уравнение регрессионной прямой: $ \\hat{y} = b_0 + b_1x $.\n",
    "\n",
    "2. Далее, построив нашу модель, мы должны узнать, насколько хорошо наша объясняет ЗП, для этого найдём коэфицент детерминации $R^2$\n",
    "$$R^2 = \\frac{\\left(\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})(y_i - \\bar{y})}\\right)^2}{\\sum\\limits_{i=1}^{N}{(x_i - \\bar{x})^2}\\sum\\limits_{i=1}^{N}{(y_i - \\bar{y})^2}}$$\n",
    "и проверим нулевую гипотезу:\n",
    "$$H0: b_1 = 0 $$\n",
    "\n",
    "3. Не столько статистическая задача, сколько задача предсказания. По данным НП мы хотим предсказать ЗП."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='hs_grad', y='poverty', data=df, kind='reg', color='m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_descr = df.describe().transpose()\n",
    "df_descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Построим модель'''\n",
    "from scipy.stats import linregress\n",
    "\n",
    "slope, intercept, r, p, std_err =  linregress(df['hs_grad'], df['poverty'])\n",
    "\n",
    "x = np.linspace(75, 100)\n",
    "\n",
    "reg = lambda x: intercept + slope*x\n",
    "plt.scatter(x='hs_grad', y='poverty', data=df, label='data')\n",
    "plt.xlabel('hs_grad %')\n",
    "plt.ylabel('poverty %')\n",
    "plt.title('Linear Regression')\n",
    "plt.plot(x, reg(x), color='r', label='fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''\n",
    "slope = {slope:.2f}\n",
    "intercept = {intercept:.2f}\n",
    "r = {r:.2f}\n",
    "R^2 = {(r ** 2):.2f}\n",
    "p = {p:.5f}\n",
    "std_err = {std_err:.3f}\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образо мы подтвердили, что данные описываются уравнением линейной регрессии со значениями коэффциентов $b_1 = -0.62$, $b_0 = 64.78$ и получили искомое значение $R^2 = 0.56$.\n",
    "\n",
    "Осталось ответить третью задачу - предсказания данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача предсказания значений зависимой переменной\n",
    "\n",
    "Попробуем ответить на вопрос: \"какое значение бедности можно ождать при уровне оброазованности равном $95%$?\"\n",
    "\n",
    "Для этого воспользуемся уравнением прямой, соответсвующей линии, описывающей наши данные - *линии тренда*.\n",
    "\n",
    "Подставим значения:\n",
    "$$\\hat{\\text{poverty}} =  b_0 + b_1 \\cdot \\hat{\\text{hs\\_grad}} = 64.78 - 0.62 \\cdot 95 = 5.77 \\%$$\n",
    "\n",
    "Стоит отметить несколько нюансов:\n",
    "1. Для использования регрессионной модели для предсказания значений величин, стоит помнить о физических ограничениях.\n",
    "    Например, если линия трендов пересечёт ось абцисс, это не значит, что уровень бедности в популяции может стать отрицательным. \n",
    "2. Линейная взаимосвязь исследуемых величин может нарушаться начиная с некоторых значений НП, тогда результаты предсказания могуть быть некорректными.\n",
    "3. Разделение на ЗП и НП уловно. Полученные значения уравнения линейной регрессии, как и в случае с корреляцией ничего не говорят нам о причино следственной связи между ЗП и НП. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регрессионный анализ с несколькими независимыми переменными\n",
    "\n",
    "### Множественная регрессия (Multiple Regression)\n",
    "\n",
    "Множественная регрессия позволяет исследовать влияние сразу нескольких независимых переменных на одну зависиммую.\n",
    "\n",
    "#### Требования к данным\n",
    "\n",
    "- линейная зависимость переменных\n",
    "- нормальное распредление остатков\n",
    "- гомоскедастичность данных\n",
    "- проверка на мультиколлиарность\n",
    "- нормальное распределение переменных (желательно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример расчёта и визуализации множественной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "df = pd.read_csv('../../data/states.csv')\n",
    "\n",
    "# Построим плоскость предсказания\n",
    "lm = smf.ols(formula='poverty ~ white + hs_grad', data=df).fit()\n",
    "mesh_size = 1.0\n",
    "margin = 2.0\n",
    "x_min, x_max = df.white.min()- margin, df.white.max() + margin\n",
    "y_min, y_max = df.hs_grad.min()- margin, df.hs_grad.max() + margin\n",
    "z_pred = lambda x, y: lm.params.white * x  + lm.params.hs_grad * y + lm.params.Intercept\n",
    "x_range = np.arange(x_min, x_max, mesh_size)\n",
    "y_range = np.arange(y_min, y_max, mesh_size)\n",
    "z_range = np.array([[z_pred(x, y) for x in x_range] for y in y_range])\n",
    "\n",
    "# какие значения выше предсказания, а какие ниже\n",
    "df['poverty_pred'] = np.array([poverty >= z_pred(df.white[i], df.hs_grad[i]) for i, poverty in df.poverty.items()])\n",
    "\n",
    "# составим график\n",
    "fig = px.scatter_3d(df, x='white', y='hs_grad', z='poverty',\n",
    "                    color='poverty_pred', color_discrete_sequence=['red', 'green'],\n",
    "                   title='зависиость процента белого населения и уровня образования на бедность населения')\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "fig.add_traces(go.Surface(x=x_range,y=y_range, z=z_range, name='prediction', opacity=0.8))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** сверху должен быть объёмный график, но если его не видно, запустите этот код у себя на компе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Выбор наилучшей модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация: логистическая регрессия и кластерный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLM и продвинутые темы\n",
    "\n",
    "Ситуация: вы учите методы статистического анализа, впервые открываете для себя линейную регрессию. Чувство могущества может опьянять - наконец-то вы можете узнавать правду о мире с помощью математики! Но едва вы прикасаетесь к реальным данным, начинаются проблемы: распределения многих переменных не ведут себя так, как этого ожидает линейная регрессия. И с этого момента ваша жизнь становится хуже.\n",
    "\n",
    "В этом уроке разберем:\n",
    "\n",
    "- Устойчивые (Робастные) методы\n",
    "- Логистическая регрессия Logistic\n",
    "- Мультиномиальная регрессия Multinominal\n",
    "- Порядковая регрессия Ordinal\n",
    "- Регрессия Пуассона Poisson\n",
    "- Регрессия выживаемости Survival\n",
    "\n",
    "### Линейная регрессия и устойчивые методы\n",
    "\n",
    "Линейная регрессия — это наш верный друг, который помогает предсказать одну величину (например, цену квартиры) на основе других (площадь, район, этаж). \n",
    "\n",
    "В основе всей классической статистики и, в частности, линейной регрессии лежит нормальное (гауссовское) распределение — та самая симметричная кривая в форме колокола, которая может принимать любые значения от минус бесконечности до плюс бесконечности.\n",
    "\n",
    "Чтобы линейная регрессия работала корректно, данные должны соблюдать несколько строгих допущений:\n",
    "1. Линейность связи: Модель ожидает, что взаимосвязь между вашими переменными можно описать прямой линией. Если зависимость изогнута, модель будет ошибаться.\n",
    "2. Нормальность остатков: Ошибки модели (разница между предсказаниями и реальными значениями) должны быть распределены по тому самому «колоколу» нормального распределения.\n",
    "3. Однородность дисперсии остатков (гомоскедастичность): Разброс ошибок должен быть примерно одинаковым на всем протяжении ваших данных. Не должно быть так, что для малых значений модель ошибается чуть-чуть, а для больших — очень сильно.\n",
    "\n",
    "В реальных данных эти допущения нарушаются «почти всегда». Особенно остро проблема встает, когда мы работаем с данными, которые по своей природе не могут быть нормально распределены. Например, ответы «да/нет», количество покупок (не может быть отрицательным) или рейтинг от 1 до 5.\n",
    "\n",
    "Конечно, для некоторых нарушений, вроде выбросов или ненормальности остатков, у нас есть первая линия обороны — устойчивые (робастные) методы. Это непараметрическая статистика вроде корреляции Спирмена или U-критерия Манна-Уитни. Они отлично справляются с локальными проблемами. Но что делать, когда все еще хуже? Когда проблема не в паре выбросов, а в том, что сама природа наших данных — их распределение — в корне отличается от нормального?\n",
    "\n",
    "Для таких «непослушных» данных и нужен более гибкий и мощный инструмент, который не пытается втиснуть всё в рамки нормальности.\n",
    "\n",
    "### Обобщённые линейные модели (GLM)\n",
    "\n",
    "GLM — это аббревиатура от Generalized Linear Models, что переводится как Обобщенные Линейные Модели. По сути, это все та же регрессия.\n",
    "\n",
    "GLM расширяет возможности классической регрессии с помощью функции связи (Link Function): Это математический «мост», который связывает наши реальные, «непослушные» данные с идеальным миром линейной модели:\n",
    "$$\n",
    "F(Y) = B_0 + B_1X_1 + ... + B_NX_N + \\xi,\n",
    "$$\n",
    "где $B_0$ - свободный член (intercept), $B_N$ - коэффициент угла наклона независимой переменной $X_N$, $\\xi$ - ошибка (остатки уравнения).\n",
    "\n",
    "Функция связи преобразует распределение зависимой $Y$ переменной так, что:\n",
    "1. Оно принимает значения от $-\\infty$ до $+\\infty$\n",
    "2. Связь зависимой переменной с предикторами линейна\n",
    "\n",
    "Пункт 1 полезен отходом от возможных нефизичных предсказаний модели. Например, обычная линейная рагрессия может предсказать в том числе и отрицательное количество покупок, что является абсурдом.\n",
    "\n",
    "Далее как функцию связи мы будем использовать натуральный логарифм - логистическую регрессию.\n",
    "\n",
    "### Логистическая регрессия\n",
    "\n",
    "Логистическая регрессия основана на биномиальном распределении и использует функцию логит, которая работает в три шага:\n",
    "    1. Вероятность (Probability): Исходная величина, которая меняется от 0 до 1. Пример: вероятность орла при броске шуллерской монетки равна 75% (0.75).\n",
    "    2. Шансы (Odds): Вероятность преобразуется в шансы (вероятность успеха / вероятность неудачи) по формуле P / (1 - P). \n",
    "    Пример: 0.75 / (1 - 0.75) = 3. Шансы 3 к 1. Шансы могут меняться от 0 до +∞.\n",
    "    3. Логит (Logit): От шансов берется натуральный логарифм. \n",
    "    Пример: ln(3). Логит как раз и меняется в нужном нам диапазоне от -∞ до +∞, что идеально подходит для линейной модели.\n",
    "\n",
    "Результат логистической регрессии — это не прямая линия, а S-образная кривая, которая плавно стремится к 0 и 1, но никогда не выходит за их пределы.\n",
    "\n",
    "Пример применения логистической регрессии смотри в ноутбуке `src\\extra\\Sorta_GLM.ipynb`.\n",
    "\n",
    "### Пробит-регрессия (Probit)\n",
    "\n",
    "### Мултиноминальная регрессия\n",
    "\n",
    "Пример применения мултиноминальной регрессии смотри в ноутбуке `src\\extra\\Sorta_GLM.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Полезные ссылки\n",
    "\n",
    "- https://gallery.shinyapps.io/dist_calc/\n",
    "    - сайт где можно визуализировать различные распределения и вести подсчёты"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
